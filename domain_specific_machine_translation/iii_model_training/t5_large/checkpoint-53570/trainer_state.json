{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 53570,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09333582228859436,
      "grad_norm": 2.4146440029144287,
      "learning_rate": 1.9813328355422813e-05,
      "loss": 1.368,
      "step": 500
    },
    {
      "epoch": 0.1866716445771887,
      "grad_norm": 2.3560056686401367,
      "learning_rate": 1.9626656710845624e-05,
      "loss": 1.2925,
      "step": 1000
    },
    {
      "epoch": 0.2800074668657831,
      "grad_norm": 2.0998406410217285,
      "learning_rate": 1.9439985066268435e-05,
      "loss": 1.2685,
      "step": 1500
    },
    {
      "epoch": 0.3733432891543774,
      "grad_norm": 1.8832130432128906,
      "learning_rate": 1.9253313421691246e-05,
      "loss": 1.246,
      "step": 2000
    },
    {
      "epoch": 0.4666791114429718,
      "grad_norm": 1.9595290422439575,
      "learning_rate": 1.9066641777114057e-05,
      "loss": 1.2259,
      "step": 2500
    },
    {
      "epoch": 0.5600149337315662,
      "grad_norm": 1.743127465248108,
      "learning_rate": 1.8879970132536868e-05,
      "loss": 1.2149,
      "step": 3000
    },
    {
      "epoch": 0.6533507560201606,
      "grad_norm": 2.3370509147644043,
      "learning_rate": 1.8693298487959683e-05,
      "loss": 1.2107,
      "step": 3500
    },
    {
      "epoch": 0.7466865783087548,
      "grad_norm": 2.43095326423645,
      "learning_rate": 1.850662684338249e-05,
      "loss": 1.2139,
      "step": 4000
    },
    {
      "epoch": 0.8400224005973492,
      "grad_norm": 2.235466241836548,
      "learning_rate": 1.8319955198805305e-05,
      "loss": 1.1728,
      "step": 4500
    },
    {
      "epoch": 0.9333582228859436,
      "grad_norm": 2.5309834480285645,
      "learning_rate": 1.8133283554228113e-05,
      "loss": 1.1575,
      "step": 5000
    },
    {
      "epoch": 1.0,
      "eval_bleu": 21.8065,
      "eval_gen_len": 17.3572,
      "eval_loss": 1.0294824838638306,
      "eval_runtime": 276.0086,
      "eval_samples_per_second": 19.405,
      "eval_steps_per_second": 2.427,
      "step": 5357
    },
    {
      "epoch": 1.0266940451745379,
      "grad_norm": 1.7701348066329956,
      "learning_rate": 1.7946611909650927e-05,
      "loss": 1.1356,
      "step": 5500
    },
    {
      "epoch": 1.1200298674631324,
      "grad_norm": 1.8921425342559814,
      "learning_rate": 1.7759940265073735e-05,
      "loss": 1.1019,
      "step": 6000
    },
    {
      "epoch": 1.2133656897517267,
      "grad_norm": 2.5251152515411377,
      "learning_rate": 1.757326862049655e-05,
      "loss": 1.0898,
      "step": 6500
    },
    {
      "epoch": 1.3067015120403211,
      "grad_norm": 2.0930323600769043,
      "learning_rate": 1.7386596975919357e-05,
      "loss": 1.0967,
      "step": 7000
    },
    {
      "epoch": 1.4000373343289154,
      "grad_norm": 1.6418992280960083,
      "learning_rate": 1.719992533134217e-05,
      "loss": 1.0821,
      "step": 7500
    },
    {
      "epoch": 1.4933731566175097,
      "grad_norm": 2.260983467102051,
      "learning_rate": 1.7013253686764983e-05,
      "loss": 1.0619,
      "step": 8000
    },
    {
      "epoch": 1.5867089789061042,
      "grad_norm": 2.1747262477874756,
      "learning_rate": 1.6826582042187794e-05,
      "loss": 1.0757,
      "step": 8500
    },
    {
      "epoch": 1.6800448011946987,
      "grad_norm": 1.8912537097930908,
      "learning_rate": 1.6639910397610605e-05,
      "loss": 1.0556,
      "step": 9000
    },
    {
      "epoch": 1.773380623483293,
      "grad_norm": 1.8786709308624268,
      "learning_rate": 1.6453238753033416e-05,
      "loss": 1.0613,
      "step": 9500
    },
    {
      "epoch": 1.8667164457718872,
      "grad_norm": 2.198551654815674,
      "learning_rate": 1.6266567108456227e-05,
      "loss": 1.07,
      "step": 10000
    },
    {
      "epoch": 1.9600522680604815,
      "grad_norm": 2.9335501194000244,
      "learning_rate": 1.6079895463879038e-05,
      "loss": 1.0557,
      "step": 10500
    },
    {
      "epoch": 2.0,
      "eval_bleu": 22.4614,
      "eval_gen_len": 17.3516,
      "eval_loss": 0.9860489964485168,
      "eval_runtime": 275.2885,
      "eval_samples_per_second": 19.456,
      "eval_steps_per_second": 2.434,
      "step": 10714
    },
    {
      "epoch": 2.0533880903490758,
      "grad_norm": 1.9750792980194092,
      "learning_rate": 1.589322381930185e-05,
      "loss": 1.0221,
      "step": 11000
    },
    {
      "epoch": 2.1467239126376705,
      "grad_norm": 2.033264398574829,
      "learning_rate": 1.570655217472466e-05,
      "loss": 0.9937,
      "step": 11500
    },
    {
      "epoch": 2.2400597349262648,
      "grad_norm": 2.3077332973480225,
      "learning_rate": 1.551988053014747e-05,
      "loss": 0.9989,
      "step": 12000
    },
    {
      "epoch": 2.333395557214859,
      "grad_norm": 1.856533408164978,
      "learning_rate": 1.5333208885570283e-05,
      "loss": 0.9969,
      "step": 12500
    },
    {
      "epoch": 2.4267313795034533,
      "grad_norm": 1.8532346487045288,
      "learning_rate": 1.5146537240993094e-05,
      "loss": 0.9979,
      "step": 13000
    },
    {
      "epoch": 2.520067201792048,
      "grad_norm": 2.281388521194458,
      "learning_rate": 1.4959865596415905e-05,
      "loss": 0.9795,
      "step": 13500
    },
    {
      "epoch": 2.6134030240806423,
      "grad_norm": 2.5266263484954834,
      "learning_rate": 1.4773193951838718e-05,
      "loss": 0.9874,
      "step": 14000
    },
    {
      "epoch": 2.7067388463692366,
      "grad_norm": 1.9430166482925415,
      "learning_rate": 1.4586522307261529e-05,
      "loss": 0.9879,
      "step": 14500
    },
    {
      "epoch": 2.800074668657831,
      "grad_norm": 1.929407000541687,
      "learning_rate": 1.439985066268434e-05,
      "loss": 0.9922,
      "step": 15000
    },
    {
      "epoch": 2.893410490946425,
      "grad_norm": 2.4979004859924316,
      "learning_rate": 1.4213179018107151e-05,
      "loss": 0.9737,
      "step": 15500
    },
    {
      "epoch": 2.9867463132350194,
      "grad_norm": 1.8800700902938843,
      "learning_rate": 1.4026507373529962e-05,
      "loss": 0.9767,
      "step": 16000
    },
    {
      "epoch": 3.0,
      "eval_bleu": 22.775,
      "eval_gen_len": 17.3527,
      "eval_loss": 0.9660695791244507,
      "eval_runtime": 282.1454,
      "eval_samples_per_second": 18.983,
      "eval_steps_per_second": 2.375,
      "step": 16071
    },
    {
      "epoch": 3.080082135523614,
      "grad_norm": 1.9490379095077515,
      "learning_rate": 1.3839835728952773e-05,
      "loss": 0.9529,
      "step": 16500
    },
    {
      "epoch": 3.1734179578122084,
      "grad_norm": 1.7811353206634521,
      "learning_rate": 1.3653164084375586e-05,
      "loss": 0.9344,
      "step": 17000
    },
    {
      "epoch": 3.2667537801008026,
      "grad_norm": 2.7060458660125732,
      "learning_rate": 1.3466492439798395e-05,
      "loss": 0.9169,
      "step": 17500
    },
    {
      "epoch": 3.360089602389397,
      "grad_norm": 2.4301364421844482,
      "learning_rate": 1.3279820795221208e-05,
      "loss": 0.9241,
      "step": 18000
    },
    {
      "epoch": 3.4534254246779916,
      "grad_norm": 2.397637367248535,
      "learning_rate": 1.3093149150644018e-05,
      "loss": 0.9332,
      "step": 18500
    },
    {
      "epoch": 3.546761246966586,
      "grad_norm": 2.4620931148529053,
      "learning_rate": 1.290647750606683e-05,
      "loss": 0.9116,
      "step": 19000
    },
    {
      "epoch": 3.64009706925518,
      "grad_norm": 2.657296895980835,
      "learning_rate": 1.271980586148964e-05,
      "loss": 0.9385,
      "step": 19500
    },
    {
      "epoch": 3.7334328915437744,
      "grad_norm": 2.3685569763183594,
      "learning_rate": 1.2533134216912453e-05,
      "loss": 0.9145,
      "step": 20000
    },
    {
      "epoch": 3.8267687138323687,
      "grad_norm": 2.214266777038574,
      "learning_rate": 1.2346462572335262e-05,
      "loss": 0.9189,
      "step": 20500
    },
    {
      "epoch": 3.920104536120963,
      "grad_norm": 2.6931211948394775,
      "learning_rate": 1.2159790927758075e-05,
      "loss": 0.9228,
      "step": 21000
    },
    {
      "epoch": 4.0,
      "eval_bleu": 23.1646,
      "eval_gen_len": 17.365,
      "eval_loss": 0.955196738243103,
      "eval_runtime": 270.6848,
      "eval_samples_per_second": 19.787,
      "eval_steps_per_second": 2.475,
      "step": 21428
    },
    {
      "epoch": 4.013440358409557,
      "grad_norm": 2.883575916290283,
      "learning_rate": 1.1973119283180886e-05,
      "loss": 0.9226,
      "step": 21500
    },
    {
      "epoch": 4.1067761806981515,
      "grad_norm": 2.077331304550171,
      "learning_rate": 1.1786447638603697e-05,
      "loss": 0.8777,
      "step": 22000
    },
    {
      "epoch": 4.200112002986747,
      "grad_norm": 2.096649646759033,
      "learning_rate": 1.1599775994026508e-05,
      "loss": 0.8828,
      "step": 22500
    },
    {
      "epoch": 4.293447825275341,
      "grad_norm": 2.2217373847961426,
      "learning_rate": 1.141310434944932e-05,
      "loss": 0.8915,
      "step": 23000
    },
    {
      "epoch": 4.386783647563935,
      "grad_norm": 1.8438663482666016,
      "learning_rate": 1.122643270487213e-05,
      "loss": 0.8718,
      "step": 23500
    },
    {
      "epoch": 4.4801194698525295,
      "grad_norm": 3.1902267932891846,
      "learning_rate": 1.1039761060294943e-05,
      "loss": 0.8864,
      "step": 24000
    },
    {
      "epoch": 4.573455292141124,
      "grad_norm": 2.620006561279297,
      "learning_rate": 1.0853089415717753e-05,
      "loss": 0.8848,
      "step": 24500
    },
    {
      "epoch": 4.666791114429718,
      "grad_norm": 1.6949158906936646,
      "learning_rate": 1.0666417771140565e-05,
      "loss": 0.8991,
      "step": 25000
    },
    {
      "epoch": 4.760126936718312,
      "grad_norm": 2.4744460582733154,
      "learning_rate": 1.0479746126563375e-05,
      "loss": 0.8723,
      "step": 25500
    },
    {
      "epoch": 4.853462759006907,
      "grad_norm": 1.831370234489441,
      "learning_rate": 1.0293074481986188e-05,
      "loss": 0.8829,
      "step": 26000
    },
    {
      "epoch": 4.946798581295501,
      "grad_norm": 2.239177942276001,
      "learning_rate": 1.0106402837408997e-05,
      "loss": 0.8707,
      "step": 26500
    },
    {
      "epoch": 5.0,
      "eval_bleu": 23.3974,
      "eval_gen_len": 17.3661,
      "eval_loss": 0.9540035128593445,
      "eval_runtime": 294.3977,
      "eval_samples_per_second": 18.193,
      "eval_steps_per_second": 2.276,
      "step": 26785
    },
    {
      "epoch": 5.040134403584095,
      "grad_norm": 2.4946229457855225,
      "learning_rate": 9.91973119283181e-06,
      "loss": 0.857,
      "step": 27000
    },
    {
      "epoch": 5.13347022587269,
      "grad_norm": 2.302624225616455,
      "learning_rate": 9.733059548254621e-06,
      "loss": 0.8481,
      "step": 27500
    },
    {
      "epoch": 5.226806048161285,
      "grad_norm": 2.1721510887145996,
      "learning_rate": 9.546387903677432e-06,
      "loss": 0.8301,
      "step": 28000
    },
    {
      "epoch": 5.320141870449879,
      "grad_norm": 1.7628437280654907,
      "learning_rate": 9.359716259100243e-06,
      "loss": 0.8437,
      "step": 28500
    },
    {
      "epoch": 5.413477692738473,
      "grad_norm": 2.3009185791015625,
      "learning_rate": 9.173044614523054e-06,
      "loss": 0.8396,
      "step": 29000
    },
    {
      "epoch": 5.506813515027067,
      "grad_norm": 2.330536127090454,
      "learning_rate": 8.986372969945865e-06,
      "loss": 0.8418,
      "step": 29500
    },
    {
      "epoch": 5.600149337315662,
      "grad_norm": 1.984954833984375,
      "learning_rate": 8.799701325368676e-06,
      "loss": 0.836,
      "step": 30000
    },
    {
      "epoch": 5.693485159604256,
      "grad_norm": 2.593971014022827,
      "learning_rate": 8.613029680791488e-06,
      "loss": 0.856,
      "step": 30500
    },
    {
      "epoch": 5.78682098189285,
      "grad_norm": 1.6047362089157104,
      "learning_rate": 8.426358036214299e-06,
      "loss": 0.836,
      "step": 31000
    },
    {
      "epoch": 5.8801568041814445,
      "grad_norm": 2.1368751525878906,
      "learning_rate": 8.239686391637111e-06,
      "loss": 0.8371,
      "step": 31500
    },
    {
      "epoch": 5.973492626470039,
      "grad_norm": 2.594869375228882,
      "learning_rate": 8.053014747059923e-06,
      "loss": 0.8457,
      "step": 32000
    },
    {
      "epoch": 6.0,
      "eval_bleu": 23.5293,
      "eval_gen_len": 17.3394,
      "eval_loss": 0.9505070447921753,
      "eval_runtime": 278.4826,
      "eval_samples_per_second": 19.233,
      "eval_steps_per_second": 2.406,
      "step": 32142
    },
    {
      "epoch": 6.066828448758634,
      "grad_norm": 2.3773820400238037,
      "learning_rate": 7.866343102482734e-06,
      "loss": 0.8251,
      "step": 32500
    },
    {
      "epoch": 6.160164271047228,
      "grad_norm": 1.9737229347229004,
      "learning_rate": 7.679671457905545e-06,
      "loss": 0.8197,
      "step": 33000
    },
    {
      "epoch": 6.2535000933358225,
      "grad_norm": 2.7507991790771484,
      "learning_rate": 7.492999813328357e-06,
      "loss": 0.7927,
      "step": 33500
    },
    {
      "epoch": 6.346835915624417,
      "grad_norm": 2.0291738510131836,
      "learning_rate": 7.306328168751168e-06,
      "loss": 0.8133,
      "step": 34000
    },
    {
      "epoch": 6.440171737913011,
      "grad_norm": 1.9879233837127686,
      "learning_rate": 7.119656524173979e-06,
      "loss": 0.8145,
      "step": 34500
    },
    {
      "epoch": 6.533507560201605,
      "grad_norm": 2.6572442054748535,
      "learning_rate": 6.93298487959679e-06,
      "loss": 0.817,
      "step": 35000
    },
    {
      "epoch": 6.6268433824901996,
      "grad_norm": 2.828556776046753,
      "learning_rate": 6.746313235019601e-06,
      "loss": 0.8113,
      "step": 35500
    },
    {
      "epoch": 6.720179204778794,
      "grad_norm": 2.5036582946777344,
      "learning_rate": 6.559641590442413e-06,
      "loss": 0.8088,
      "step": 36000
    },
    {
      "epoch": 6.813515027067388,
      "grad_norm": 2.367750644683838,
      "learning_rate": 6.372969945865224e-06,
      "loss": 0.796,
      "step": 36500
    },
    {
      "epoch": 6.906850849355983,
      "grad_norm": 2.5947823524475098,
      "learning_rate": 6.186298301288035e-06,
      "loss": 0.8191,
      "step": 37000
    },
    {
      "epoch": 7.0,
      "eval_bleu": 23.5809,
      "eval_gen_len": 17.3491,
      "eval_loss": 0.9533613324165344,
      "eval_runtime": 269.3384,
      "eval_samples_per_second": 19.886,
      "eval_steps_per_second": 2.488,
      "step": 37499
    },
    {
      "epoch": 7.0001866716445775,
      "grad_norm": 2.0066843032836914,
      "learning_rate": 5.999626656710846e-06,
      "loss": 0.8177,
      "step": 37500
    },
    {
      "epoch": 7.093522493933172,
      "grad_norm": 2.557211399078369,
      "learning_rate": 5.8129550121336575e-06,
      "loss": 0.7958,
      "step": 38000
    },
    {
      "epoch": 7.186858316221766,
      "grad_norm": 3.444035291671753,
      "learning_rate": 5.626283367556469e-06,
      "loss": 0.7924,
      "step": 38500
    },
    {
      "epoch": 7.28019413851036,
      "grad_norm": 3.2343053817749023,
      "learning_rate": 5.43961172297928e-06,
      "loss": 0.7952,
      "step": 39000
    },
    {
      "epoch": 7.373529960798955,
      "grad_norm": 2.1933858394622803,
      "learning_rate": 5.252940078402091e-06,
      "loss": 0.782,
      "step": 39500
    },
    {
      "epoch": 7.466865783087549,
      "grad_norm": 3.5272068977355957,
      "learning_rate": 5.066268433824903e-06,
      "loss": 0.7903,
      "step": 40000
    },
    {
      "epoch": 7.560201605376143,
      "grad_norm": 2.3645541667938232,
      "learning_rate": 4.879596789247714e-06,
      "loss": 0.7843,
      "step": 40500
    },
    {
      "epoch": 7.653537427664737,
      "grad_norm": 1.9347002506256104,
      "learning_rate": 4.692925144670525e-06,
      "loss": 0.7977,
      "step": 41000
    },
    {
      "epoch": 7.746873249953332,
      "grad_norm": 2.222311019897461,
      "learning_rate": 4.506253500093336e-06,
      "loss": 0.7841,
      "step": 41500
    },
    {
      "epoch": 7.840209072241926,
      "grad_norm": 2.1372742652893066,
      "learning_rate": 4.319581855516147e-06,
      "loss": 0.7775,
      "step": 42000
    },
    {
      "epoch": 7.933544894530521,
      "grad_norm": 2.229358196258545,
      "learning_rate": 4.132910210938958e-06,
      "loss": 0.7931,
      "step": 42500
    },
    {
      "epoch": 8.0,
      "eval_bleu": 23.5323,
      "eval_gen_len": 17.354,
      "eval_loss": 0.9531596302986145,
      "eval_runtime": 276.3315,
      "eval_samples_per_second": 19.383,
      "eval_steps_per_second": 2.425,
      "step": 42856
    },
    {
      "epoch": 8.026880716819115,
      "grad_norm": 2.7750134468078613,
      "learning_rate": 3.946238566361769e-06,
      "loss": 0.7872,
      "step": 43000
    },
    {
      "epoch": 8.120216539107709,
      "grad_norm": 2.4152562618255615,
      "learning_rate": 3.7595669217845814e-06,
      "loss": 0.7687,
      "step": 43500
    },
    {
      "epoch": 8.213552361396303,
      "grad_norm": 2.7010881900787354,
      "learning_rate": 3.572895277207393e-06,
      "loss": 0.7764,
      "step": 44000
    },
    {
      "epoch": 8.3068881836849,
      "grad_norm": 2.245164632797241,
      "learning_rate": 3.386223632630204e-06,
      "loss": 0.7806,
      "step": 44500
    },
    {
      "epoch": 8.400224005973493,
      "grad_norm": 3.265625,
      "learning_rate": 3.199551988053015e-06,
      "loss": 0.7752,
      "step": 45000
    },
    {
      "epoch": 8.493559828262088,
      "grad_norm": 2.550832748413086,
      "learning_rate": 3.012880343475826e-06,
      "loss": 0.7737,
      "step": 45500
    },
    {
      "epoch": 8.586895650550682,
      "grad_norm": 2.515507936477661,
      "learning_rate": 2.8262086988986377e-06,
      "loss": 0.7711,
      "step": 46000
    },
    {
      "epoch": 8.680231472839276,
      "grad_norm": 3.0450100898742676,
      "learning_rate": 2.639537054321449e-06,
      "loss": 0.7815,
      "step": 46500
    },
    {
      "epoch": 8.77356729512787,
      "grad_norm": 2.377791404724121,
      "learning_rate": 2.45286540974426e-06,
      "loss": 0.7709,
      "step": 47000
    },
    {
      "epoch": 8.866903117416465,
      "grad_norm": 3.1520256996154785,
      "learning_rate": 2.266193765167071e-06,
      "loss": 0.767,
      "step": 47500
    },
    {
      "epoch": 8.960238939705059,
      "grad_norm": 3.1220858097076416,
      "learning_rate": 2.0795221205898826e-06,
      "loss": 0.7663,
      "step": 48000
    },
    {
      "epoch": 9.0,
      "eval_bleu": 23.5515,
      "eval_gen_len": 17.3579,
      "eval_loss": 0.954251766204834,
      "eval_runtime": 276.5737,
      "eval_samples_per_second": 19.366,
      "eval_steps_per_second": 2.423,
      "step": 48213
    },
    {
      "epoch": 9.053574761993653,
      "grad_norm": 4.677956581115723,
      "learning_rate": 1.8928504760126939e-06,
      "loss": 0.7763,
      "step": 48500
    },
    {
      "epoch": 9.146910584282248,
      "grad_norm": 1.9007352590560913,
      "learning_rate": 1.7061788314355052e-06,
      "loss": 0.7615,
      "step": 49000
    },
    {
      "epoch": 9.240246406570842,
      "grad_norm": 2.8602378368377686,
      "learning_rate": 1.5195071868583163e-06,
      "loss": 0.7673,
      "step": 49500
    },
    {
      "epoch": 9.333582228859436,
      "grad_norm": 2.1050827503204346,
      "learning_rate": 1.3328355422811276e-06,
      "loss": 0.7629,
      "step": 50000
    },
    {
      "epoch": 9.42691805114803,
      "grad_norm": 1.9936963319778442,
      "learning_rate": 1.1461638977039387e-06,
      "loss": 0.7584,
      "step": 50500
    },
    {
      "epoch": 9.520253873436625,
      "grad_norm": 3.1290135383605957,
      "learning_rate": 9.594922531267503e-07,
      "loss": 0.7575,
      "step": 51000
    },
    {
      "epoch": 9.613589695725219,
      "grad_norm": 3.0515799522399902,
      "learning_rate": 7.728206085495614e-07,
      "loss": 0.7732,
      "step": 51500
    },
    {
      "epoch": 9.706925518013813,
      "grad_norm": 2.7182860374450684,
      "learning_rate": 5.861489639723726e-07,
      "loss": 0.7553,
      "step": 52000
    },
    {
      "epoch": 9.800261340302407,
      "grad_norm": 2.1251649856567383,
      "learning_rate": 3.994773193951839e-07,
      "loss": 0.7612,
      "step": 52500
    },
    {
      "epoch": 9.893597162591002,
      "grad_norm": 2.7120795249938965,
      "learning_rate": 2.1280567481799516e-07,
      "loss": 0.7646,
      "step": 53000
    },
    {
      "epoch": 9.986932984879596,
      "grad_norm": 1.890869140625,
      "learning_rate": 2.6134030240806425e-08,
      "loss": 0.7541,
      "step": 53500
    },
    {
      "epoch": 10.0,
      "eval_bleu": 23.567,
      "eval_gen_len": 17.356,
      "eval_loss": 0.9559276103973389,
      "eval_runtime": 268.97,
      "eval_samples_per_second": 19.913,
      "eval_steps_per_second": 2.491,
      "step": 53570
    }
  ],
  "logging_steps": 500,
  "max_steps": 53570,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.2018605115392e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
